{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line content: 0 0.2492578125 0.27639274102964123 0.135625 0.28871099999999994\n",
      "Split values: ['0', '0.2492578125', '0.27639274102964123', '0.135625', '0.28871099999999994']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Define the paths\n",
    "image_folder = 'Face_Detection/images/val'\n",
    "labels_folder = 'Face_Detection/labels/val'\n",
    "\n",
    "# The image you want to plot\n",
    "target_image = 'd44b475f4eda66d8.jpg'  # Replace with the exact image name\n",
    "\n",
    "# Derive the corresponding .txt file for the target image\n",
    "label_file = os.path.join(labels_folder, target_image.replace('.jpg', '.txt'))\n",
    "\n",
    "# Load the bounding box from the .txt file (in YOLO format)\n",
    "bbox = None\n",
    "if os.path.exists(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        # Assuming the .txt file contains YOLO format: class_id, x_center, y_center, width, height (all normalized)\n",
    "        line = f.readline().strip()\n",
    "        print(f\"Line content: {line}\")  # Debugging line to check the contents\n",
    "        values = line.split()\n",
    "        print(f\"Split values: {values}\")  # Debugging line to check split values\n",
    "        if len(values) == 5:\n",
    "            class_id, x_center, y_center, bbox_width, bbox_height = [float(value) for value in values]  # Ignore class_id\n",
    "            bbox = [x_center, y_center, bbox_width, bbox_height]\n",
    "        else:\n",
    "            print(f\"Unexpected format: {values}\")\n",
    "#print(bbox)\n",
    "# If the bounding box was found, plot the image with PIL\n",
    "if bbox:\n",
    "    image_path = os.path.join(image_folder, target_image)\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        # Open the image using PIL\n",
    "        image = Image.open(image_path)\n",
    "        img_width, img_height = image.size\n",
    "        \n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # YOLO format gives normalized center coordinates and size, we need to convert to (x_min, y_min, x_max, y_max)\n",
    "        x_center, y_center, bbox_width, bbox_height = bbox\n",
    "        \n",
    "        # Convert YOLO format to corner format (x_min, y_min, x_max, y_max)\n",
    "        x_min = (x_center - bbox_width / 2) * img_width\n",
    "        y_min = (y_center - bbox_height / 2) * img_height\n",
    "        x_max = (x_center + bbox_width / 2) * img_width\n",
    "        y_max = (y_center + bbox_height / 2) * img_height\n",
    "        \n",
    "        # Draw the bounding box on the image\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=3)\n",
    "        \n",
    "        # Display the image with bounding box\n",
    "        image.show()\n",
    "    else:\n",
    "        print(f\"Image {target_image} not found.\")\n",
    "else:\n",
    "    print(f\"Bounding box for {target_image} not found in the label file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'Face_Detection/labels/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m#landmarks_file = 'list_landmarks_align_celeba.csv'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m# The image you want to plot\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#target_image = '000009.jpg'  # Replace with the name of the image you want to plot\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# Load the bounding box for the specific image\u001b[39;00m\n\u001b[1;32m     16\u001b[0m bbox \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(annotations_file, newline\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictReader(f)\n\u001b[1;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m reader:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'Face_Detection/labels/train/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define the paths\n",
    "image_folder = 'Face_Detection/images/train/'\n",
    "annotations_file = 'Face_Detection/labels/train/'\n",
    "#landmarks_file = 'list_landmarks_align_celeba.csv'\n",
    "\n",
    "# The image you want to plot\n",
    "#target_image = '000009.jpg'  # Replace with the name of the image you want to plot\n",
    "\n",
    "# Load the bounding box for the specific image\n",
    "bbox = None\n",
    "with open(annotations_file, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['image_id'] == target_image:\n",
    "            bbox = [int(row['x_1']), int(row['y_1']), int(row['width']), int(row['height'])]\n",
    "            break\n",
    "print(bbox)\n",
    "# If the bounding box was found, plot the image\n",
    "if bbox:\n",
    "    image_path = os.path.join(image_folder, target_image)\n",
    "    if os.path.exists(image_path):\n",
    "        # Open the image\n",
    "        image = Image.open(image_path).resize((512, 512))\n",
    "\n",
    "        \n",
    "        # Create a plot\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        # Add bounding box (bbox in format x_min, y_min, width, height)\n",
    "        x_min, y_min, width, height = bbox\n",
    "        rect = patches.Rectangle((x_min-30, y_min-30), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Image {target_image} not found.\")\n",
    "else:\n",
    "    print(f\"Bounding box for {target_image} not found in the annotations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypts_data_path = \"list_landmarks_align_celeba.csv\"\n",
    "images_data_path = \"face_images/face_images/img_align_celeba\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keypts_og' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_face_bbox\u001b[39m(index, df\u001b[39m=\u001b[39mkeypts_og, size\u001b[39m=\u001b[39moriginal_image_size):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This function plots the face image with its keypoints and bounding box\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     img \u001b[39m=\u001b[39m imread_index(index, size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keypts_og' is not defined"
     ]
    }
   ],
   "source": [
    "def imread_index(index, size=image_size_training, path=images_data_path):\n",
    "    \"\"\"This function helps read images based on the its index by converting it to an array.\n",
    "    \"\"\"\n",
    "    path = \"{}/{}\".format(str(path), str(keypts_og.iloc[index].image_id))\n",
    "    \n",
    "    #read the image\n",
    "    image = PIL.Image.open(path).resize(size)\n",
    "    image_array = np.asarray(image)\n",
    "    \n",
    "    return image_array\n",
    "#Get a list of all key points of the face\n",
    "def img_keypts_list(index, df=keypts_og):\n",
    "    \"\"\" This function returns a list of all the key points of the face image so \n",
    "    it's easier to plot\n",
    "    \"\"\"\n",
    "    points_list = [df.iloc[index].lefteye_x, df.iloc[index].lefteye_y,\n",
    "                  df.iloc[index].righteye_x, df.iloc[index].righteye_y,\n",
    "                  df.iloc[index].nose_x, df.iloc[index].nose_y,\n",
    "                  df.iloc[index].leftmouth_x, df.iloc[index].leftmouth_y,\n",
    "                  df.iloc[index].rightmouth_x, df.iloc[index].rightmouth_y]\n",
    "    \n",
    "    return points_list\n",
    "def plot_face_bbox(index, df=keypts_og, size=original_image_size):\n",
    "    \"\"\" This function plots the face image with its keypoints and bounding box\n",
    "    \"\"\"\n",
    "    img = imread_index(index, size)\n",
    "    points_list = img_keypts_list(index, df)\n",
    "    \n",
    "    #Plotting the image\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    #Plot the face points\n",
    "    ax.plot(points_list[::2], points_list[1::2], 'bo-')\n",
    "    \n",
    "    #Plot bounding box\n",
    "    width = abs(points_list[0] - points_list[8] - 60) #obtain width from left eye x to right mouth x\n",
    "    height = abs(points_list[1] - points_list[9] - 75)#obtain width from left eye y to right mouth y\n",
    "    rect = patches.Rectangle((points_list[0]-30, points_list[1]-40), width, height, linewidth=4, edgecolor='g', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    #Remove axis\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6c4f747fa2c7780c986bfcd90656f719e986ea9812b99278856877bc5c8f753"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
